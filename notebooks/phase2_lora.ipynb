{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11942420,"sourceType":"datasetVersion","datasetId":7507648}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Data Uploading and Preprocessing","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\n\n# ─── CONFIG ───────────────────────────────────────────────────────────\nDATASET_ROOT = \"/kaggle/input/is584dataset/dataset\"  # adjust if needed\nASPECT_PATH  = os.path.join(DATASET_ROOT, \"aspect_data\", \"review_with_aspect.jsonl\")\nCONFS        = [\n    \"ICLR_2017\",\"ICLR_2018\",\"ICLR_2019\",\"ICLR_2020\",\n    \"NIPS_2016\",\"NIPS_2017\",\"NIPS_2018\",\"NIPS_2019\"\n]\n# ────────────────────────────────────────────────────────────────────────\n\ndef extract_text_fields(doc):\n    \"\"\"Recursively collect all string values >50 chars from a nested JSON.\"\"\"\n    texts = []\n    def recurse(o):\n        if isinstance(o, str):\n            if len(o.strip()) > 50:\n                texts.append(o.strip())\n        elif isinstance(o, list):\n            for item in o:\n                recurse(item)\n        elif isinstance(o, dict):\n            for v in o.values():\n                recurse(v)\n    recurse(doc)\n    return \"\\n\\n\".join(texts) if texts else None\n\n# 1) Load full paper texts\npaper_records = []\nfor conf in CONFS:\n    content_dir = os.path.join(DATASET_ROOT, conf, f\"{conf}_content\")\n    if not os.path.isdir(content_dir):\n        continue\n    for fn in os.listdir(content_dir):\n        if not fn.endswith(\"_content.json\"):\n            continue\n        path = os.path.join(content_dir, fn)\n        doc = json.load(open(path, \"r\"))\n        sid = fn.replace(\"_content.json\", \"\")\n        text = extract_text_fields(doc)\n        paper_records.append({\"submission_id\": sid, \"paper_text\": text})\npaper_df = pd.DataFrame(paper_records)\n\n# 2) Flatten aspect spans\nasp_recs = []\nwith open(ASPECT_PATH, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        obj    = json.loads(line)\n        sid    = obj[\"id\"]\n        revtxt = obj[\"text\"]\n        for st, ed, lbl in obj[\"labels\"]:\n            span = revtxt[st:ed].strip()\n            if not span:\n                continue\n            asp_recs.append({\n                \"submission_id\":   sid,\n                \"review_text\":     revtxt,\n                \"aspect\":          lbl,\n                \"aspect_sentence\": span\n            })\naspect_df = pd.DataFrame(asp_recs)\n\n# 3) Merge papers + aspects, drop missing texts\ndf = aspect_df.merge(paper_df, on=\"submission_id\", how=\"left\")\ndf = df[df[\"paper_text\"].notna()].reset_index(drop=True)\n\n# 4) Filter to core aspects\ncore = [\"clarity_positive\",\"clarity_negative\",\"soundness_positive\",\"soundness_negative\",\"motivation_positive\",\"motivation_negative\"]\ndf = df[df[\"aspect\"].isin(core)]\n\n# 5) Final fields\ndf = df[[\"paper_text\",\"review_text\",\"aspect\",\"aspect_sentence\"]]\n\n# Quick sanity check\nprint(\"✔ df shape:\", df.shape)\nprint(df[\"aspect\"].value_counts().head())\nprint(df.head())\n\n# ——— Sanitize text columns to remove/replace problematic chars ———\nfor col in [\"paper_text\", \"review_text\", \"aspect_sentence\"]:\n    df[col] = df[col].apply(\n        lambda x: x.encode(\"utf-8\", \"ignore\").decode(\"utf-8\") if isinstance(x, str) else x\n    )\n\n# Now save without error\ndf.to_csv(\"phase2_dataset.csv\", index=False, encoding=\"utf-8\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:58:18.345937Z","iopub.execute_input":"2025-05-27T18:58:18.346742Z","iopub.status.idle":"2025-05-27T19:01:36.983777Z","shell.execute_reply.started":"2025-05-27T18:58:18.346716Z","shell.execute_reply":"2025-05-27T19:01:36.983204Z"}},"outputs":[{"name":"stdout","text":"✔ df shape: (71854, 4)\naspect\nclarity_negative       15697\nsoundness_negative     15662\nclarity_positive       13095\nsoundness_positive     12780\nmotivation_positive    11121\nName: count, dtype: int64\n                                          paper_text  \\\n1  Deep neural networks (DNNs) have achieved impe...   \n2  Deep neural networks (DNNs) have achieved impe...   \n3  Deep neural networks (DNNs) have achieved impe...   \n6  Deep neural networks (DNNs) have achieved impe...   \n8  A long-term goal in artificial intelligence is...   \n\n                                         review_text               aspect  \\\n1  This work studies the predictive uncertainty i...  motivation_positive   \n2  This work studies the predictive uncertainty i...     clarity_positive   \n3  This work studies the predictive uncertainty i...   soundness_negative   \n6  This work studies the predictive uncertainty i...   soundness_negative   \n8  Summary : This paper proposes a new approach t...  motivation_positive   \n\n                                     aspect_sentence  \n1  The issue researched in this work is of signif...  \n2  The motivation , research issues and the propo...  \n3  The current recommendation is Weak Reject beca...  \n6  The novelty and significance of fine-tuning th...  \n8                       This paper is well motivated  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\n\n# ─── CONFIG ───────────────────────────────────────────────────────────\nDATASET_ROOT = \"/kaggle/input/is584dataset/dataset\"  # adjust if needed\nASPECT_PATH  = os.path.join(DATASET_ROOT, \"aspect_data\", \"review_with_aspect.jsonl\")\nCONFS        = [\n    \"ICLR_2017\",\"ICLR_2018\",\"ICLR_2019\",\"ICLR_2020\",\n    \"NIPS_2016\",\"NIPS_2017\",\"NIPS_2018\",\"NIPS_2019\"\n]\nCORE_ASPECTS = {\n    \"clarity_positive\",\"clarity_negative\",\n    \"soundness_positive\",\"soundness_negative\",\n    \"motivation_positive\",\"motivation_negative\"\n}\n# ────────────────────────────────────────────────────────────────────────\n\ndef extract_text_fields(doc):\n    \"\"\"Collect all string values ≥50 chars from nested JSON.\"\"\"\n    texts = []\n    def recurse(o):\n        if isinstance(o, str):\n            if len(o.strip()) > 50:\n                texts.append(o.strip())\n        elif isinstance(o, dict):\n            for v in o.values():\n                recurse(v)\n        elif isinstance(o, list):\n            for item in o:\n                recurse(item)\n    recurse(doc)\n    return \"\\n\\n\".join(texts) if texts else None\n\n# 1) Load full paper texts\npaper_records = []\nfor conf in CONFS:\n    content_dir = os.path.join(DATASET_ROOT, conf, f\"{conf}_content\")\n    if not os.path.isdir(content_dir):\n        continue\n    for fn in os.listdir(content_dir):\n        if not fn.endswith(\"_content.json\"):\n            continue\n        sid = fn.replace(\"_content.json\", \"\")\n        doc = json.load(open(os.path.join(content_dir, fn), \"r\"))\n        text = extract_text_fields(doc)\n        if text:\n            paper_records.append({\"submission_id\": sid, \"paper_text\": text})\npaper_df = pd.DataFrame(paper_records)\nprint(f\"→ Loaded {len(paper_df)} papers\")\n\n# 2) Load aspect spans\nasp_recs = []\nwith open(ASPECT_PATH, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        obj    = json.loads(line)\n        sid    = obj[\"id\"]\n        revtxt = obj[\"text\"]\n        for st, ed, lbl in obj[\"labels\"]:\n            span = revtxt[st:ed].strip()\n            if span:\n                asp_recs.append({\n                    \"submission_id\":   sid,\n                    \"review_text\":     revtxt,\n                    \"aspect\":          lbl,\n                    \"aspect_sentence\": span\n                })\naspect_df = pd.DataFrame(asp_recs)\nprint(f\"→ Loaded {len(aspect_df)} aspect‐span entries\")\n\n# 3) Load all reviews, parse rating+confidence, pick top‐confidence one per paper\ndef parse_lead_int(s):\n    \"\"\"If s like '4: ...', return 4 else 0.\"\"\"\n    if not isinstance(s, str) or \":\" not in s:\n        return 0\n    try:\n        return int(s.split(\":\",1)[0])\n    except:\n        return 0\n\nrev_recs = []\nfor conf in CONFS:\n    rev_dir = os.path.join(DATASET_ROOT, conf, f\"{conf}_review\")\n    if not os.path.isdir(rev_dir):\n        continue\n    for fn in os.listdir(rev_dir):\n        if not fn.endswith(\"_review.json\"):\n            continue\n        data = json.load(open(os.path.join(rev_dir, fn), \"r\"))\n        root = data.get(\"root\", data)\n        sid  = root.get(\"id\", fn.replace(\"_review.json\",\"\"))\n        for rv in root.get(\"reviews\", []):\n            txt = rv.get(\"review\",\"\").strip()\n            if not txt:\n                continue\n            rating     = parse_lead_int(rv.get(\"rating\",\"\"))\n            confidence = parse_lead_int(rv.get(\"confidence\",\"\"))\n            rev_recs.append({\n                \"submission_id\": sid,\n                \"review\":        txt,\n                \"rating\":        rating,\n                \"confidence\":    confidence\n            })\n\nrev_df = pd.DataFrame(rev_recs)\nprint(f\"→ Loaded {len(rev_df)} raw review entries\")\n\nbest_rev = (\n    rev_df\n    .sort_values(\n        [\"submission_id\",\"confidence\",\"rating\"],\n        ascending=[True, False, False]\n    )\n    .groupby(\"submission_id\", as_index=False)\n    .first()[[\"submission_id\",\"review\",\"confidence\"]]\n)\nprint(f\"→ Selected {len(best_rev)} best‐confidence reviews\")\n\n# 4) Merge papers + aspects + chosen reviews\ndf = (\n    aspect_df\n    .merge(paper_df,  on=\"submission_id\", how=\"left\")\n    .merge(best_rev,  on=\"submission_id\", how=\"left\")\n    .dropna(subset=[\"paper_text\",\"review_text\"])\n    .reset_index(drop=True)\n)\n\n# 5) Keep only core aspects\ndf = df[df[\"aspect\"].isin(CORE_ASPECTS)]\n\n# 6) Deduplicate per paper+aspect: pick the longest aspect_sentence\ndf[\"span_len\"] = df[\"aspect_sentence\"].str.len()\ndf = (\n    df\n    .sort_values(\n        [\"submission_id\", \"aspect\", \"span_len\"],\n        ascending=[True, True, False]\n    )\n    .drop_duplicates([\"submission_id\"], keep=\"first\")\n    .drop(columns=\"span_len\")\n)\n\n# 7) Sanitize and save\nfor col in [\"paper_text\", \"review\", \"aspect_sentence\"]:\n    df[col] = (df[col]\n               .astype(str)\n               .apply(lambda x: x.encode(\"utf-8\",\"ignore\")\n                                .decode(\"utf-8\")))\ndf.to_csv(\"phase2_dataset.csv\", index=False, encoding=\"utf-8\")\nprint(f\"✔ Final dataset: {len(df)} rows\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:01:36.984770Z","iopub.execute_input":"2025-05-27T19:01:36.984949Z","iopub.status.idle":"2025-05-27T19:03:33.091362Z","shell.execute_reply.started":"2025-05-27T19:01:36.984928Z","shell.execute_reply":"2025-05-27T19:03:33.090778Z"}},"outputs":[{"name":"stdout","text":"→ Loaded 8850 papers\n→ Loaded 148086 aspect‐span entries\n→ Loaded 28122 raw review entries\n→ Selected 8780 best‐confidence reviews\n✔ Final dataset: 8704 rows\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T17:23:38.923923Z","iopub.execute_input":"2025-05-27T17:23:38.924201Z","iopub.status.idle":"2025-05-27T17:23:38.945999Z","shell.execute_reply.started":"2025-05-27T17:23:38.924180Z","shell.execute_reply":"2025-05-27T17:23:38.945411Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        submission_id                                        review_text  \\\n121061    ICLR_2017_1  This is a very interesting and fairly easy to ...   \n31763    ICLR_2017_10  * *Edit : Based on the discussion below , my m...   \n135807  ICLR_2017_100  In this paper , the authors use a separate int...   \n122259  ICLR_2017_101  This was an interesting paper . The algorithm ...   \n419     ICLR_2017_102  The paper proposes a new memory access scheme ...   \n59132   ICLR_2017_103  This paper points out that you can take an LST...   \n124269  ICLR_2017_104  The authors propose a recurrent neural network...   \n66336   ICLR_2017_105  This paper explores ensemble optimisation in t...   \n66731   ICLR_2017_106  In this paper a well known soft mixture of exp...   \n77127   ICLR_2017_107  This paper proposes an approach to learning wo...   \n\n                     aspect  \\\n121061     clarity_positive   \n31763      clarity_negative   \n135807     clarity_positive   \n122259     clarity_positive   \n419        clarity_negative   \n59132      clarity_negative   \n124269     clarity_positive   \n66336      clarity_positive   \n66731   motivation_positive   \n77127      clarity_positive   \n\n                                          aspect_sentence  \\\n121061  As a non-expert on this topic , it was easy to...   \n31763               There are also other typos throughout   \n135807           The organization is generally very clear   \n122259  The algorithm seems clear , the problem well-r...   \n419     The difference to the properties of normal NTM...   \n59132   Unfortunately , this simple , effective and in...   \n124269  In general the paper is well written and quite...   \n66336          The paper is well written and accessible .   \n66731   This is clearly an interesting direction of fu...   \n77127                        The paper is clearly written   \n\n                                               paper_text  \\\n121061  MAKING NEURAL PROGRAMMING ARCHITECTURES GENERA...   \n31763   Q-PROP: SAMPLE-EFFICIENT POLICY GRADIENT WITH ...   \n135807  INTROSPECTION:ACCELERATING NEURAL NETWORK TRAI...   \n122259  The task of hyperparameter optimization is bec...   \n419     Recent work on neural Turing machines (NTMs) (...   \n59132   Recurrent neural networks (RNNs), including ga...   \n124269  In order to plan and act effectively, agent-ba...   \n66336   EPOPT: LEARNING ROBUST NEURAL NETWORK POLICIES...   \n66731   Transferring knowledge from prior source tasks...   \n77127   MULTI-VIEW RECURRENT NEURAL ACOUSTIC WORD EMBE...   \n\n                                                   review  confidence  \n121061  This paper improves significantly upon the ori...           5  \n31763   **Edit: Based on the discussion below, my main...           5  \n135807  EDIT: Updated score. See additional comment.\\n...           5  \n122259  This paper discusses Hyperband, an extension o...           5  \n419     *** Paper Summary ***\\n\\nThis paper formalizes...           4  \n59132   This paper introduces a novel RNN architecture...           4  \n124269  [UPDATE]\\nAfter going through the response fro...           5  \n66336   This paper explores ensemble optimisation in t...           4  \n66731   In this paper a well known soft mixture of exp...           4  \n77127   This paper proposes an approach to learning wo...           4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission_id</th>\n      <th>review_text</th>\n      <th>aspect</th>\n      <th>aspect_sentence</th>\n      <th>paper_text</th>\n      <th>review</th>\n      <th>confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>121061</th>\n      <td>ICLR_2017_1</td>\n      <td>This is a very interesting and fairly easy to ...</td>\n      <td>clarity_positive</td>\n      <td>As a non-expert on this topic , it was easy to...</td>\n      <td>MAKING NEURAL PROGRAMMING ARCHITECTURES GENERA...</td>\n      <td>This paper improves significantly upon the ori...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>31763</th>\n      <td>ICLR_2017_10</td>\n      <td>* *Edit : Based on the discussion below , my m...</td>\n      <td>clarity_negative</td>\n      <td>There are also other typos throughout</td>\n      <td>Q-PROP: SAMPLE-EFFICIENT POLICY GRADIENT WITH ...</td>\n      <td>**Edit: Based on the discussion below, my main...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>135807</th>\n      <td>ICLR_2017_100</td>\n      <td>In this paper , the authors use a separate int...</td>\n      <td>clarity_positive</td>\n      <td>The organization is generally very clear</td>\n      <td>INTROSPECTION:ACCELERATING NEURAL NETWORK TRAI...</td>\n      <td>EDIT: Updated score. See additional comment.\\n...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>122259</th>\n      <td>ICLR_2017_101</td>\n      <td>This was an interesting paper . The algorithm ...</td>\n      <td>clarity_positive</td>\n      <td>The algorithm seems clear , the problem well-r...</td>\n      <td>The task of hyperparameter optimization is bec...</td>\n      <td>This paper discusses Hyperband, an extension o...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>419</th>\n      <td>ICLR_2017_102</td>\n      <td>The paper proposes a new memory access scheme ...</td>\n      <td>clarity_negative</td>\n      <td>The difference to the properties of normal NTM...</td>\n      <td>Recent work on neural Turing machines (NTMs) (...</td>\n      <td>*** Paper Summary ***\\n\\nThis paper formalizes...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>59132</th>\n      <td>ICLR_2017_103</td>\n      <td>This paper points out that you can take an LST...</td>\n      <td>clarity_negative</td>\n      <td>Unfortunately , this simple , effective and in...</td>\n      <td>Recurrent neural networks (RNNs), including ga...</td>\n      <td>This paper introduces a novel RNN architecture...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>124269</th>\n      <td>ICLR_2017_104</td>\n      <td>The authors propose a recurrent neural network...</td>\n      <td>clarity_positive</td>\n      <td>In general the paper is well written and quite...</td>\n      <td>In order to plan and act effectively, agent-ba...</td>\n      <td>[UPDATE]\\nAfter going through the response fro...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>66336</th>\n      <td>ICLR_2017_105</td>\n      <td>This paper explores ensemble optimisation in t...</td>\n      <td>clarity_positive</td>\n      <td>The paper is well written and accessible .</td>\n      <td>EPOPT: LEARNING ROBUST NEURAL NETWORK POLICIES...</td>\n      <td>This paper explores ensemble optimisation in t...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>66731</th>\n      <td>ICLR_2017_106</td>\n      <td>In this paper a well known soft mixture of exp...</td>\n      <td>motivation_positive</td>\n      <td>This is clearly an interesting direction of fu...</td>\n      <td>Transferring knowledge from prior source tasks...</td>\n      <td>In this paper a well known soft mixture of exp...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>77127</th>\n      <td>ICLR_2017_107</td>\n      <td>This paper proposes an approach to learning wo...</td>\n      <td>clarity_positive</td>\n      <td>The paper is clearly written</td>\n      <td>MULTI-VIEW RECURRENT NEURAL ACOUSTIC WORD EMBE...</td>\n      <td>This paper proposes an approach to learning wo...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df[\"aspect\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T17:23:38.946620Z","iopub.execute_input":"2025-05-27T17:23:38.946866Z","iopub.status.idle":"2025-05-27T17:23:38.954086Z","shell.execute_reply.started":"2025-05-27T17:23:38.946851Z","shell.execute_reply":"2025-05-27T17:23:38.953531Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"aspect\nclarity_negative       6245\nclarity_positive       1959\nmotivation_positive     219\nmotivation_negative     137\nsoundness_negative      111\nsoundness_positive       33\nName: count, dtype: int64"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# ─── Load the prepared dataset ──────────────────────────────────────────\ndf = pd.read_csv(\"/kaggle/working/phase2_dataset.csv\")\n\n# Display overall class distribution\nprint(\"Overall aspect distribution:\")\nprint(df[\"aspect\"].value_counts(), \"\\n\")\n\n# ─── 1) Split off final test set (20% of data) ─────────────────────────\n# We stratify by 'aspect' to keep class balance across splits.\ntrain_val, test = train_test_split(\n    df,\n    test_size=0.20,\n    stratify=df[\"aspect\"],\n    random_state=42\n)\n\nprint(f\"Train+Val shape: {train_val.shape}\")\nprint(f\"Test shape:        {test.shape}\\n\")\n\n# ─── 2) Split train_val into train (80% of original) and val (10% of original) ─────────────────────────\n# Since train_val is 80% of original, using test_size=0.125 yields 10% of original for validation.\ntrain, val = train_test_split(\n    train_val,\n    test_size=0.125,\n    stratify=train_val[\"aspect\"],\n    random_state=42\n)\n\nprint(f\"Train shape: {train.shape}\")\nprint(f\"Val shape:   {val.shape}\")\nprint(f\"Test shape:  {test.shape}\\n\")\n\n# ─── 3) Verify class distribution in each split ─────────────────────────\nprint(\"Class distribution in TRAIN set:\")\nprint(train[\"aspect\"].value_counts(), \"\\n\")\n\nprint(\"Class distribution in VAL set:\")\nprint(val[\"aspect\"].value_counts(), \"\\n\")\n\nprint(\"Class distribution in TEST set:\")\nprint(test[\"aspect\"].value_counts(), \"\\n\")\n\n# ─── 4) Save splits to CSV for modeling ────────────────────────────────\ntrain.to_csv(\"train.csv\", index=False)\nval.to_csv(\"val.csv\",     index=False)\ntest.to_csv(\"test.csv\",   index=False)\n\nprint(\"Saved train.csv, val.csv, test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:03:33.092161Z","iopub.execute_input":"2025-05-27T19:03:33.092354Z","iopub.status.idle":"2025-05-27T19:03:52.304053Z","shell.execute_reply.started":"2025-05-27T19:03:33.092337Z","shell.execute_reply":"2025-05-27T19:03:52.303373Z"}},"outputs":[{"name":"stdout","text":"Overall aspect distribution:\naspect\nclarity_negative       6245\nclarity_positive       1959\nmotivation_positive     219\nmotivation_negative     137\nsoundness_negative      111\nsoundness_positive       33\nName: count, dtype: int64 \n\nTrain+Val shape: (6963, 7)\nTest shape:        (1741, 7)\n\nTrain shape: (6092, 7)\nVal shape:   (871, 7)\nTest shape:  (1741, 7)\n\nClass distribution in TRAIN set:\naspect\nclarity_negative       4371\nclarity_positive       1371\nmotivation_positive     153\nmotivation_negative      96\nsoundness_negative       78\nsoundness_positive       23\nName: count, dtype: int64 \n\nClass distribution in VAL set:\naspect\nclarity_negative       625\nclarity_positive       196\nmotivation_positive     22\nmotivation_negative     14\nsoundness_negative      11\nsoundness_positive       3\nName: count, dtype: int64 \n\nClass distribution in TEST set:\naspect\nclarity_negative       1249\nclarity_positive        392\nmotivation_positive      44\nmotivation_negative      27\nsoundness_negative       22\nsoundness_positive        7\nName: count, dtype: int64 \n\nSaved train.csv, val.csv, test.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Baseline Model - Zero shot with longllama","metadata":{}},{"cell_type":"code","source":"# 1) Imports & Installs\n# ─────────────────────────────────────────────────────────────────────\n!pip install -q wandb evaluate transformers peft bitsandbytes rouge_score bert_score\nimport os, random, pandas as pd, numpy as np, wandb\nimport torch\nimport evaluate\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    GenerationConfig,\n    Trainer,\n    TrainingArguments,\n    DataCollatorForSeq2Seq,\n    set_seed\n)\nfrom peft import LoraConfig, get_peft_model\nfrom bitsandbytes import __version__ as bnb_version ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:03:52.305544Z","iopub.execute_input":"2025-05-27T19:03:52.305743Z","iopub.status.idle":"2025-05-27T19:05:42.592628Z","shell.execute_reply.started":"2025-05-27T19:03:52.305728Z","shell.execute_reply":"2025-05-27T19:05:42.591831Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-05-27 19:05:24.892898: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748372725.108889      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748372725.171267      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"wandb.login(key=\"0e48c15605abf65402208cd05becaa061bf0dfbf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:42.593588Z","iopub.execute_input":"2025-05-27T19:05:42.594283Z","iopub.status.idle":"2025-05-27T19:05:49.200761Z","shell.execute_reply.started":"2025-05-27T19:05:42.594248Z","shell.execute_reply":"2025-05-27T19:05:49.199842Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mesrasekerci\u001b[0m (\u001b[33mesrasekerci-metu-middle-east-technical-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# 2) Configuration & Seeds\n# ─────────────────────────────────────────────────────────────────────\nPROJECT     = \"is584-phase2\"\nMODEL_ID    = \"syzymon/long_llama_3b_instruct\"\nTRAIN_FILE  = \"train.csv\"\nVAL_FILE    = \"val.csv\"\nTEST_FILE   = \"test.csv\"\nOUTPUT_DIR  = \"./phase2_outputs\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nSEED        = 42\nBATCH       = 8\nMAX_IN      = 512\nMAX_OUT     = 64\nLORA_RANKS  = [8, 16]\nEPOCHS      = 1\nLR          = 2e-4\nDEVICE      = \"cuda\"\nset_seed(SEED)\ntorch.manual_seed(SEED)\nrandom.seed(SEED)\n\n# 3) Load Data Splits\n# ─────────────────────────────────────────────────────────────────────\ndf_train = pd.read_csv(TRAIN_FILE)\ndf_val   = pd.read_csv(VAL_FILE)\ndf_test  = pd.read_csv(TEST_FILE)\n\n# 4) Initialize Tokenizer & Base Model (FP16, GPU)\n# ─────────────────────────────────────────────────────────────────────\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n).eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:49.201765Z","iopub.execute_input":"2025-05-27T19:05:49.202914Z","iopub.status.idle":"2025-05-27T19:06:34.956295Z","shell.execute_reply.started":"2025-05-27T19:05:49.202891Z","shell.execute_reply":"2025-05-27T19:06:34.955740Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/913 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f017f8c53ce45ac993adf137baf54fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/512k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56ade0d2be9f4f97a49467c3dbbf3f09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1833b64296542df85ba5979664be90d"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\nYou are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9a22b4eba5a4973b3093a0797ec957c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_longllama.py:   0%|          | 0.00/6.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be8a24871bd4598a1b5b7265518f8e0"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/syzymon/long_llama_3b_instruct:\n- configuration_longllama.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_longllama.py:   0%|          | 0.00/65.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fdbce0fae94430cac0a84e81874b378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"longllama_utils.py:   0%|          | 0.00/2.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b17807b9d094d88868e46fb3b5ac3c9"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/syzymon/long_llama_3b_instruct:\n- longllama_utils.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/syzymon/long_llama_3b_instruct:\n- modeling_longllama.py\n- longllama_utils.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/6.85G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64726fa526d74188a1e1a2cdef89a150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.85G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84e509f1b7824dde8861e964326841e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ba3985f97f40ad9495c764fc1e193d"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df_train = df_train.dropna(subset=['review'])\ndf_val   = df_val.dropna(subset=['review'])\ndf_test  = df_test.dropna(subset=['review'])\n\n# 5) Build Prompts & References\n# ─────────────────────────────────────────────────────────────────────\ndef build_prompts(df):\n    P, R = [], []\n    for _, row in df.iterrows():\n        p = row.paper_text.replace(\"\\n\",\" \")[:2000]\n        rv= row.review.replace(\"\\n\",\" \")[:1000]\n        asp = row.aspect\n        prompt = (\n            f\"Paper Excerpt:\\n{p}\\n\\n\"\n            f\"Previous Review:\\n{rv}\\n\\n\"\n            f\"Aspect: {asp}\\n\\n\"\n            \"Task: Generate exactly one new sentence focusing on this aspect.\"\n        )\n        P.append(prompt)\n        R.append(row.aspect_sentence)\n    return P, R\n\ntrain_prompts, train_refs = build_prompts(df_train)\nval_prompts,   val_refs   = build_prompts(df_val)\ntest_prompts,  test_refs  = build_prompts(df_test)\n\n# 6) Tokenize for Trainer\n# ─────────────────────────────────────────────────────────────────────\ndef tokenize_for_train(prompts, refs):\n    enc = tokenizer(prompts, truncation=True, max_length=MAX_IN,\n                    padding=\"max_length\", return_tensors=\"pt\")\n    with tokenizer.as_target_tokenizer():\n        labs = tokenizer(refs, truncation=True, max_length=MAX_OUT,\n                         padding=\"max_length\", return_tensors=\"pt\")[\"input_ids\"]\n    enc[\"labels\"] = labs\n    return enc\n\ntrain_ds = tokenize_for_train(train_prompts, train_refs)\nval_ds   = tokenize_for_train(val_prompts,   val_refs)\n\n# 7) Data Collator & Metric Computation\n# ─────────────────────────────────────────────────────────────────────\ncollator = DataCollatorForSeq2Seq(tokenizer, model=base_model)\n\nbleu  = evaluate.load(\"bleu\")\nrouge = evaluate.load(\"rouge\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    dec_p = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    dec_l = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    refs_wrapped = [[l] for l in dec_l]\n    b = bleu.compute(predictions=dec_p, references=refs_wrapped)[\"bleu\"]\n    r = rouge.compute(predictions=dec_p, references=dec_l,\n                      rouge_types=[\"rouge1\",\"rouge2\",\"rougeL\"])\n    return {\n        \"bleu\": b,\n        \"rouge1\": r[\"rouge1\"].mid.fmeasure,\n        \"rouge2\": r[\"rouge2\"].mid.fmeasure,\n        \"rougeL\": r[\"rougeL\"].mid.fmeasure\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:06:34.957120Z","iopub.execute_input":"2025-05-27T19:06:34.957396Z","iopub.status.idle":"2025-05-27T19:06:47.323149Z","shell.execute_reply.started":"2025-05-27T19:06:34.957372Z","shell.execute_reply":"2025-05-27T19:06:47.322286Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"171962ab1a7844739f15c19c611b84f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb5b79258374a46878c4b40645e20c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49843695792542bd95326951e9ee6d4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa7edb0202742c296789680bc58eee9"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# 8) Zero-Shot Baseline (FP16 Generation + W&B + CSV)\n# ─────────────────────────────────────────────────────────────────────\nwandb.init(project=PROJECT, name=\"zero-shot\", reinit=True)\n\ngen_cfg = GenerationConfig(\n    max_new_tokens=MAX_OUT,\n    temperature=0.7,\n    top_p=0.9,\n    do_sample=True,\n    repetition_penalty=1.1\n)\n\nfrom tqdm.auto import tqdm\n\ndef run_zero_shot(df, prompts, refs, split):\n    preds = []\n    # tqdm for inference progress\n    for i in tqdm(range(0, len(prompts), BATCH), desc=f\"{split} zero-shot\"):\n        batch = prompts[i : i + BATCH]\n        enc = tokenizer(\n            batch,\n            return_tensors=\"pt\",\n            truncation=True,\n            padding=True,\n            max_length=MAX_IN\n        ).to(DEVICE)\n        outs = base_model.generate(**enc, generation_config=gen_cfg)\n        for seq, mask in zip(outs, enc.attention_mask):\n            L = mask.sum().item()\n            preds.append(tokenizer.decode(seq[L:], skip_special_tokens=True))\n\n    # Compute BLEU\n    b = bleu.compute(predictions=preds, references=[[r] for r in refs])[\"bleu\"]\n\n    # Compute ROUGE and normalize\n    raw = rouge.compute(predictions=preds, references=refs,\n                        rouge_types=[\"rouge1\",\"rouge2\",\"rougeL\"])\n    def _fm(val):\n        # if it’s a Score object, grab val.mid.fmeasure, else assume float\n        return getattr(val, \"mid\", val).fmeasure if hasattr(val, \"mid\") else float(val)\n    r1 = _fm(raw[\"rouge1\"])\n    r2 = _fm(raw[\"rouge2\"])\n    rL = _fm(raw[\"rougeL\"])\n\n    # Log to W&B\n    wandb.log({\n        f\"{split}/zs_bleu\": b,\n        f\"{split}/zs_r1\":   r1,\n        f\"{split}/zs_r2\":   r2,\n        f\"{split}/zs_rL\":   rL\n    })\n\n    # Save predictions\n    out = df.copy()\n    out[\"pred_zs\"] = preds\n    out.to_csv(f\"{OUTPUT_DIR}/{split}_zs.csv\", index=False)\n\n# Run with progress bars\nrun_zero_shot(df_val,  val_prompts,  val_refs,  \"val\")\nrun_zero_shot(df_test, test_prompts, test_refs, \"test\")\nwandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### LoRA finetuning with 2 hyperparameter configurations","metadata":{}},{"cell_type":"code","source":"import gc\n\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:22:58.744946Z","iopub.execute_input":"2025-05-27T19:22:58.745264Z","iopub.status.idle":"2025-05-27T19:22:59.293219Z","shell.execute_reply.started":"2025-05-27T19:22:58.745234Z","shell.execute_reply":"2025-05-27T19:22:59.292459Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"28427"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"BATCH = 1\n# Update tokenization\ndef tokenize_for_causal_lm(prompts, refs):\n    examples = []\n    for p, r in zip(prompts, refs):\n        # Compose the full string: prompt + response (expected completion)\n        full = p + \" \" + r\n        # Tokenize the full input\n        tok = tokenizer(full, truncation=True, max_length=MAX_IN, padding=\"max_length\")\n        # Find index where response starts (for masking)\n        prompt_tok = tokenizer(p, truncation=True, max_length=MAX_IN, padding=\"max_length\")\n        prompt_len = sum([1 for t in prompt_tok[\"attention_mask\"] if t == 1])\n        label = [-100]*prompt_len + tok[\"input_ids\"][prompt_len:]\n        label = label[:MAX_IN]  # make sure no length mismatch\n        # Truncate/pad label\n        while len(label) < MAX_IN:\n            label.append(-100)\n        item = {\n            \"input_ids\": torch.tensor(tok[\"input_ids\"]),\n            \"attention_mask\": torch.tensor(tok[\"attention_mask\"]),\n            \"labels\": torch.tensor(label)\n        }\n        examples.append(item)\n    return examples\n\n# Dataset wrapper for Trainer\nclass ListDataset(torch.utils.data.Dataset):\n    def __init__(self, examples):\n        self.examples = examples\n    def __getitem__(self, idx):\n        return self.examples[idx]\n    def __len__(self):\n        return len(self.examples)\n\n# Prepare datasets\ntrain_ds = tokenize_for_causal_lm(train_prompts, train_refs)\nval_ds   = tokenize_for_causal_lm(val_prompts,   val_refs)\ntrain_dataset = ListDataset(train_ds)\nval_dataset   = ListDataset(val_ds)\n\n# 9) LoRA Fine-Tuning (legacy Trainer, compatible with old transformers)\n# ─────────────────────────────────────────────────────────────────────\nfrom peft import LoraConfig, get_peft_model\n\nfor rank in LORA_RANKS:\n    wandb_run = wandb.init(project=PROJECT, name=f\"lora_r{rank}\", reinit=True)\n\n    # 9.1) Attach LoRA adapters to base model\n    peft_config = LoraConfig(\n        r=rank,\n        lora_alpha=16,\n        target_modules=[\"q_proj\", \"v_proj\"],\n        lora_dropout=0.05,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\"\n    )\n    model = get_peft_model(base_model, peft_config).to(DEVICE)\n\n    # 9.2) Trainer arguments (only basic/old options)\n    training_args = TrainingArguments(\n        output_dir=f\"{OUTPUT_DIR}/lora_r{rank}\",\n        per_device_train_batch_size=BATCH,\n        per_device_eval_batch_size=BATCH,\n        learning_rate=LR,\n        num_train_epochs=EPOCHS,\n        logging_dir=f\"{OUTPUT_DIR}/logs\",\n        fp16=True,\n        seed=SEED,\n        max_steps=1000\n    )\n\n    # 9.4) Trainer instantiation\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        data_collator=collator,\n        compute_metrics=compute_metrics,\n        tokenizer=tokenizer,\n    )\n\n    # 9.5) Training & Save\n    trainer.train()\n    trainer.save_model(f\"{OUTPUT_DIR}/lora_r{rank}/final\")\n    tokenizer.save_pretrained(f\"{OUTPUT_DIR}/lora_r{rank}/final\")\n\n    # 9.6) Evaluate on test split with LoRA model\n    def generate_and_eval(prompts, refs, split):\n        preds = []\n        for i in tqdm(range(0, len(prompts), BATCH), desc=f\"{split} lora_r{rank}\"):\n            batch = prompts[i : i + BATCH]\n            enc = tokenizer(\n                batch,\n                return_tensors=\"pt\",\n                truncation=True,\n                padding=True,\n                max_length=MAX_IN\n            ).to(DEVICE)\n            outs = model.generate(**enc, generation_config=gen_cfg)\n            for seq, mask in zip(outs, enc.attention_mask):\n                L = mask.sum().item()\n                preds.append(tokenizer.decode(seq[L:], skip_special_tokens=True))\n\n        # Metrics\n        b = bleu.compute(predictions=preds, references=[[r] for r in refs])[\"bleu\"]\n        raw = rouge.compute(predictions=preds, references=refs,\n                            rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"])\n        def _fm(val):\n            return getattr(val, \"mid\", val).fmeasure if hasattr(val, \"mid\") else float(val)\n        r1 = _fm(raw[\"rouge1\"])\n        r2 = _fm(raw[\"rouge2\"])\n        rL = _fm(raw[\"rougeL\"])\n\n        # W&B Logging\n        wandb.log({\n            f\"{split}/lora{rank}_bleu\": b,\n            f\"{split}/lora{rank}_r1\":   r1,\n            f\"{split}/lora{rank}_r2\":   r2,\n            f\"{split}/lora{rank}_rL\":   rL\n        })\n\n        # Save outputs\n        out = pd.DataFrame({\"prompt\": prompts, \"ref\": refs, \"pred\": preds})\n        out.to_csv(f\"{OUTPUT_DIR}/{split}_lora_r{rank}.csv\", index=False)\n\n    # Validation + Test Generation and Evaluation\n    generate_and_eval(val_prompts,  val_refs,  \"val\")\n    generate_and_eval(test_prompts, test_refs, \"test\")\n\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:23:00.928915Z","iopub.execute_input":"2025-05-27T19:23:00.929515Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lora_r8</strong> at: <a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2/runs/4ilk972v' target=\"_blank\">https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2/runs/4ilk972v</a><br> View project at: <a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2' target=\"_blank\">https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250527_192242-4ilk972v/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250527_192333-0q4s3i19</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2/runs/0q4s3i19' target=\"_blank\">lora_r8</a></strong> to <a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2' target=\"_blank\">https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2/runs/0q4s3i19' target=\"_blank\">https://wandb.ai/esrasekerci-metu-middle-east-technical-university/is584-phase2/runs/0q4s3i19</a>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/1922023414.py:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='42' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  42/1000 00:46 < 18:44, 0.85 it/s, Epoch 0.01/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null}]}